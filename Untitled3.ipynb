{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP556, Ecole Polytechnique, 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 5 - Régression empirique pour l'approximation d'espérance conditionnelle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.  Un exemple de programmation dynamique pour un problème d'arrêt optimal\n",
    "\n",
    "On considère le processus stochastique à deux pas \n",
    "\n",
    "$$X_i = x_0 \\ e^{-\\frac12 \\sigma^2 T_i \\ + \\ \\sigma \\, W_{i}}, \\quad\n",
    "\\qquad i=0,1,2,\n",
    "$$\n",
    "\n",
    "où $x_0$ et $\\sigma$ sont deux paramètres positifs, $T_i=i$, et $(W_i)_{0\\le i \\le 2}$ est un processus à temps discret définit comme suit: $W_0 = 0$, et \n",
    "\n",
    "- la v.a.  $W_{1}$ suit une loi Gaussienne $\\mathcal{N}(0,T_1)$,\n",
    "\n",
    "\n",
    "- $W_{2} = W_{1} + \\Delta W$, où $\\Delta W$ est une v.a. de loi $\\mathcal{N}(0,T_2 - T_1)$ indépendante de $W_{1}$.\n",
    "\n",
    "\n",
    "__Pour la terminologie__: \n",
    "\n",
    " - $(W_i)_{0\\le i \\le 2}$ est la version en temps discret de ce que l'on appelle un _mouvement Brownien_, un processus défini en temps continu.\n",
    " \n",
    "   En particulier, c'est une chaîne de Markov par rapport à sa filtration $(\\mathcal{F}_0, \\mathcal{F}_1, \\mathcal{F}_2)$, où $\\mathcal{F}_i = \\sigma(W_0, \\dots, W_i)$.\n",
    "\n",
    "\n",
    " - Le processus $(X_i)_{0\\le i \\le 2}$ est appelé _mouvement Brownien géometrique_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Le problème d'arrêt optimal__\n",
    "\n",
    "Dans la suite, on voit le processus $X$ comme modèle aléatoire pour la valeur d'un actif sur un marché (par exemple, une action).\n",
    "\n",
    "C'est un modèle à temps discret sur deux périodes ($[T_0, T_1]$ et $[T_1, T_2]$), très simplifié donc, mais la nature du problème et la méthode de calcul présentée ci-dessous restent les mêmes si on passe à un système à $n$ dates $T_1,\\dots, T_n$.\n",
    "\n",
    "$\\blacktriangleright$ Le contrat financier _option Put Bermuda_ est un exemple de jeu à arrêt optimal entre deux parties (l'acheteur et le vendeur du contrat): l'acheteur du Put Bermuda paye au vendeur un prix $u_0$ à l'instant $T_0$, et gagne en échange le droit de recevoir le montant $(K-X_t)^+ = \\max(K-X_t, 0)$ à une date $t\\in\\{0,1,2 \\}$ de son choix.\n",
    "\n",
    "La constante $K > 0$ est fixée dès le départ (alors que la date d'exercice $t$ du contrat ne l'est pas: elle est arrêtée par l'acheteur pendant la vie du produit).\n",
    "\n",
    "$\\blacktriangleright$ On peut justifier que le juste prix à attribuer à ce produit financier à la date $T_0$ est donné par\n",
    "\n",
    "$$\n",
    "u_0 = \\sup_{\\tau \\, \\in \\, \\mathcal{T}_2 } {\\mathbb E} \\left[ (K - X_\\tau)^+ \\right],\n",
    "$$\n",
    "\n",
    "où $\\mathcal{T}_2$ est l'ensemble de temps d'arrêt à valeurs dans $\\{0,T_1,T_2\\}$ par rapport à la filtration $(\\mathcal{F}_i)_{0\\le i \\le 2}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__La transformation en équation dynamique rétrograde__\n",
    "\n",
    "On souhaite évaluer $u_0$ par une méthode Monte-Carlo. \n",
    "\n",
    "On remarquera que la définition de $u_0$ contient un $\\sup$ sur un ensemble infini de fonctions (l'ensemble $\\mathcal{T}_2$ de temps d'arrêt).\n",
    "\n",
    "Une manière de simplifier le calcul est de faire appel à la formulation dynamique du problème: en posant \n",
    "\n",
    "$$\n",
    "Y_i = \\mbox{ess}\\sup_{\\tau \\,  \\in \\,  \\mathcal{T}_2: \\, \\tau \\, \\ge \\, i}\n",
    "{\\mathbb E} \\left[ (K - X_\\tau)^+|\\mathcal F_{i} \\right],\n",
    "$$\n",
    "\n",
    "de telle manière que\n",
    "$$\n",
    "Y_0 = u_0,\n",
    "$$\n",
    "\n",
    "on peut montrer que le processus $(Y_i)_{0 \\le i \\le 2}$ obéit à l'équation rétrograde\n",
    "\n",
    "$$\n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "&Y_2 = (K-X_2)^+\n",
    "\\\\\n",
    "&Y_i = \\max \\left( (K-X_i)^+, \\, {\\mathbb E} \\left[Y_{i+1}|\\mathcal{F}_i\\right] \\right)\n",
    "\\qquad i = 0, 1.\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "qui est l'_équation de programmation dynamique_ pour le problème d'arrêt optimal $u_0$. C'est cette équation que nous allons approcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Question préliminaire: \n",
    "Montrer que $Y_i$ est de la forme $Y_i= u_i (W_i)$ pour une fonction mesurable $u_i: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "Remarquer que le prix de l'option Bermuda en $t=0$ s'écrit comme l'espérance emboitée suivante\n",
    "\n",
    "$$\n",
    "u_0 = Y_0\n",
    "= \\max \\left\\{ (K-x_0)^+, {\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] \\right\\},\n",
    "$$\n",
    "\n",
    "où $v_1(W_1) = {\\mathbb E}\\left[(K-X_2)^+|W_1 \\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ On note $(W_1^m,W_2^m)_{1 \\le m \\le M}$ un échantillon de tirages i.i.d. du couple $(W_1,W_2)$, et on pose $X_i^m = x_0 \\, e^{-\\frac12 \\sigma^2 T_i \\, + \\, \\sigma \\, W_i^m}$ pour tout $m$.\n",
    "\n",
    "\n",
    "1. __Valeur de référence (_benchmark_) du prix: on utilise l'expression explicite de la fonction $v_1$.__ Dans cette question, on utilisera la formule\n",
    "\t\n",
    "    $$\n",
    "  v_1(w) = {\\mathbb E}\\left[(K-X_2)^+|W_1 = w \\right] = \n",
    "  K \\, N(-d_2) - x \\, N(-d_1)\n",
    "\t$$\n",
    "    où\n",
    "\t$$\n",
    "\tx = x_0  \\, e^{-\\frac12 \\sigma^2 T_1 + \\sigma \\, w},\n",
    "\t\\qquad d_2 = \\frac{\\log(x/K)}{\\sigma \\sqrt{T_2-T_1}} - \\frac12 \\sigma \\sqrt{T_2-T_1},\n",
    "\t\\qquad d_1 = d_2 + \\sigma \\sqrt{T_2-T_1},\n",
    "\t$$\n",
    "    \n",
    "\toù $N(z) = \\int_{-\\infty}^z e^{-y^2/2} \\frac{dy}{\\sqrt{2 \\pi}}$ est la fonction de répartition gaussienne, accessible en Python via la fonction `scipy.stats.norm.cdf`.\n",
    "    \n",
    "    (Remarque: Dans la terminologie financière, la fonction $\\mathrm{v_1}$ est le prix d'une option Put (non Bermuda, mais *Européenne*) dans le modèle de Black-Scholes.)\n",
    "    \n",
    "    __1 (a)__. Coder la formule ci-dessus pour la fonction $v_1$. Vérifier que pour les paramètres $x_0=1$, $T_1=1$, $T_2=2 $, $K=1.2$, $\\sigma=0.2$, on obtient bien $v_1(0) \\approx 0.2374$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from time import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parametres\n",
    "K = 1.2\n",
    "x0 = 1.\n",
    "sigma = 0.2\n",
    " \n",
    "T2 = 2.\n",
    "T1 = T2 / 2.\n",
    " \n",
    "M = int(5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23742104895721394\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## Q1 (a): formule explicite\n",
    "##         pour l'esperance conditionnelle \n",
    "###################################################\n",
    " \n",
    "def fonction_v_1(x0, T1, T2, K, W1, sigma):\n",
    "    \"\"\"\n",
    "    La fonction v_1(W1) de la question 1.(a)\n",
    "    \n",
    "    Autrement dit: le prix en T1 du Put Black-Scholes de maturite T2\n",
    "    en fonction de la valeur courante du mouv Brownien en T1.\n",
    "    \n",
    "    Paramètres:\n",
    "    W1: un array numpy\n",
    "    \"\"\"\n",
    "    sigmaSqrtDeltaT = sigma * np.sqrt(T2 - T1)\n",
    "     \n",
    "    ######################################\n",
    "    # TO DO: coder la formule explicite\n",
    "    # pour la fonction v_1\n",
    "    ######################################\n",
    "        \n",
    "    d2 = (np.log(x0/K) + sigma*W1 - 0.5*sigma*sigma*T1 ) / sigmaSqrtDeltaT - 0.5*sigmaSqrtDeltaT\n",
    "    d1 = d2 + sigmaSqrtDeltaT\n",
    "    \n",
    "    return  K*norm.cdf(-d2) - x0*np.exp(sigma*W1 - 0.5*sigma*sigma*T1)*norm.cdf(-d1) \n",
    "    ## Output: un array de la meme taille que W\n",
    "    return np.zeros(np.size(W1))\n",
    "\n",
    "\n",
    "print(fonction_v_1(x0, T1, T2, K, 0, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La connaissance explicite de la fonction $v_1$ permet d'écrire l'estimateur\n",
    "$$\n",
    "u_0^{M} =\n",
    "\\max \\Bigl\\{ (K-x_0)^+, \\frac 1M \\sum_{m = 1}^M u_1(W_{1}^m)\\Bigr\\}\n",
    "$$\n",
    "\n",
    "où $u_1(W_{1}^m) = \\max\\left( (K - X_{1}^m)^+, v_1(W_{1}^m) \\right)$.\n",
    "\n",
    "\n",
    "__1 (c)__ Simuler cet estimateur dans la cellule suivante. Pour calculer le maximum $\\max(a,b)$ entre deux nombres, on pourra utiliser la fonction `numpy.maximum(a,b)`.\n",
    "\n",
    "$\\blacktriangleright$ __TCL pour $u_0^{M}$__. On rappelle que la méthode delta (ou méthode de substitution) affirme que si $\\overline Y_M$ est la moyenne empirique d'une suite $(Y_m)_{m \\ge 1}$ de v.a. i.i.d. de carré intégrable et $f$ une fonction dérivable au point $\\mathbb E[Y]$, l'estimateur $f(\\overline Y_M)$ de $f(\\mathbb E [Y])$ satisfait un TCL:\n",
    "\n",
    "$$ \n",
    "\\frac 1{\\sqrt{M}} \\left( f(\\overline Y_M) - f(\\mathbb E [Y]) \\right)\n",
    "\\to \n",
    "\\mathcal N \\left(0, f'(\\mathbb E [Y])^2 \\mathrm{Var}(Y) \\right).\n",
    "$$\n",
    "\n",
    "Pour les valeurs considérées des paramètres, on peut montrer que l'on a\n",
    "\n",
    "$$\n",
    "{\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] > (K-x_0)^+.\n",
    "$$\n",
    "\n",
    "L'estimateur $u_0^{M}$ satisfait-il un TCL? Avec quelle variance limite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix benchmark = 0.2483 +/- 0.0039 \n",
      "\n",
      "Erreur relative (TCL) = 0.016 \n",
      "\n",
      "Time: 0.0020 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## On genere les tirages gaussiens et on construit\n",
    "## le mouv Brownien W et le mouv Brownien géometrique\n",
    "## aux instants T1 et T2\n",
    "###################################################\n",
    "def MBG(x0, T, sigma, W):\n",
    "    \"\"\"\n",
    "    Processus X: mouvement Brownien géometrique à\n",
    "    l'instant T, de parametre de volatilite sigma,\n",
    "    a partir de la valeur du mouvement Brownien W\n",
    "    \"\"\"\n",
    "    return x0 * np.exp(-0.5*sigma*sigma*T + sigma * W)\n",
    " \n",
    "time0 = time()\n",
    " \n",
    "#################################################\n",
    "## TO DO: Remplacer W1, W2 avec un echantillon de\n",
    "## tirages du mouvement Brownien aux dates T1 et T2\n",
    "## et X1, X2 avec le MBG correspondant\n",
    "W1 = np.sqrt(T1) * np.random.randn(M) # gaussiennes N(0,T_1)\n",
    "W2 = W1 + np.sqrt(T2-T1) * np.random.randn(M) # W1 + gaussiennes N(0,T_2-T_1) independantes\n",
    "\n",
    "X1 = MBG(x0, T1, sigma, W1)\n",
    "X2 = MBG(x0, T2, sigma, W2)\n",
    "################################################\n",
    " \n",
    "time0_1 = time()\n",
    " \n",
    "timeSimulations = time0_1 - time0\n",
    " \n",
    "###################################################\n",
    "### 1. Prix Benchmark\n",
    "###################################################\n",
    " \n",
    "time1 = time()\n",
    " \n",
    "v_1 = fonction_v_1(x0, T1, T2, K, W1, sigma)\n",
    " \n",
    "################################################\n",
    "## TO DO: completer avec le calcul du prix\n",
    "## benchmark u_0^M et l'estimation de la variance\n",
    "## dans le TCL pour l'estimateur\n",
    "u_1=np.maximum(v_1,np.maximum(K-X1,0))\n",
    "prix_benchmark = np.maximum(np.mean(u_1),np.maximum(K-x0,0))\n",
    "var_TCL = np.var(u_1)\n",
    "################################################\n",
    " \n",
    "rayonIC = 1.96 * np.sqrt(var_TCL/M)\n",
    " \n",
    "time2 = time()\n",
    " \n",
    "print(\"Prix benchmark = %1.4f +/- %1.4f \\n\" %(prix_benchmark, rayonIC) )\n",
    "print(\"Erreur relative (TCL) = %1.3f \\n\" %(rayonIC / prix_benchmark) )\n",
    "print(\"Time: %1.4f \\n\" %(time2 - time1 + timeSimulations) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Prix par régression empirique:__ \n",
    "\n",
    "   En pratique (si le modèle est plus complexe qu'un mouvement Brownien géometrique, ou s'il y a plus que trois dates $T_0, \\dots, T_n$), la fonction à injecter dans l'estimateur Monte-Carlo (ici $v_1$) n'est pas connue explicitement.\n",
    "\n",
    "   Nous allons donc l'estimer, à partir des même tirages $(X_1^m, X_2^m)$, avec une méthode de régression sur un espace d'approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On choisit comme espace d'approximation pour la fonction $v_1$ l'espace engendré par les fonctions indicatrices de $n$ intervalles disjoints:\n",
    "$$\n",
    "\\phi_k = 1_{I_k},\n",
    "\\quad\n",
    "\\mbox{où }\n",
    "I_k = \\left[-a + (k-1) \\frac{2a}n, -a + k \\frac{2a}n \\right[;\n",
    "\\quad a > 0, \n",
    "\\quad k = 1, \\dots, n\n",
    "$$\n",
    "$$\n",
    "\\text{Vect}(\\phi_1,\\dots, \\phi_n)\n",
    "= \\left\\{\\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot): \\alpha_1, \\dots, \\alpha_n \\in \\mathbb{R} \\right\\}.\n",
    "$$\n",
    "  On remarquera que $\\cup_k I_k = [-a, a[$: $a$ est donc un paramètre de troncature (toute fonction d'approximation obtenue sera nulle en dehors de cet intervalle).\n",
    "\n",
    "  On notera $\\alpha \\cdot \\phi(\\cdot) = \\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - L'approximation empirique de la fonction $v_1(\\cdot)$ est donnée par\n",
    "$$\n",
    "\\tilde v_1(\\cdot) = \\sum_{k=1}^{n} \\alpha_k^* \\ 1_{I_k}(\\cdot)\n",
    "$$\n",
    "où\n",
    "$$ \\label{e:regrEmp}\n",
    "\\begin{aligned}\n",
    "\\alpha^* \\in \\underset{\\alpha\\in \\mathbb{R}^n}{\\rm arg\\min}\n",
    "\\ \\sum_{m = 1}^M\n",
    "\\left((K-X_2^m)^+ - \\alpha \\cdot \\phi(W_1^m)\\right)^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Si l'argmin n'est pas unique, on choisira le $\\alpha^*$ de norme minimale dans $\\mathbb{R}^n$.\n",
    "\n",
    "L'estimateur par régression empirique du prix du Put Bermuda est maintenant\n",
    "$$\n",
    "\\tilde{u}_0^{M} = \n",
    "\\max \\Bigl\\{\n",
    "(K - x_0)^+, \\frac 1M \\sum_{m=1}^M \\tilde u_1(W_1^m)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où $\\tilde u_1(W_1^m) =  \\max \\left( (K - X_{1}^m)^+, \\tilde{v}_1(W_1^m) \\right)$.\n",
    "\n",
    "__2 (a) Question théorique__: Donner l'expression des coefficients de régression $\\alpha^*_k$ qui sont solution du problème d'optimisation ci-dessus.\n",
    "\n",
    "__2 (b) suite__: Utiliser l'expression obtenue pour compléter la fonction coeffsRegressionEmpirique dans la cellule ci-dessous. Compléter le calcul de l'estimateur $\\tilde{u}_0^{M}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix par regression empirique = 0.2500\n",
      "Time: 0.0025 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd632752340>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################\n",
    "### 2. Prix par regression empirique\n",
    "###################################################\n",
    " \n",
    "##################################\n",
    "### On genere les cellules I_k\n",
    "##################################\n",
    "# Choix de la troncature\n",
    "a = 3.*np.sqrt(T1)\n",
    " \n",
    "## Dimension n  de l'espace d'approximation.\n",
    "## Une règle pratique : prendre n de l'ordre de M^{d / (d+2)}\n",
    "n = int(M**(1./3))\n",
    " \n",
    "intervals = np.linspace(-a, a, n+1)\n",
    " \n",
    "####################################################\n",
    "## TO DO: calculer\n",
    "## - Les coefficients de regression empirique alpha\n",
    "## - Le vecteur v_1_tilde(W1) de taille M\n",
    "##   dans l'array v_1_tilde\n",
    "####################################################\n",
    "def regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma):\n",
    "    step = intervals[1] - intervals[0]\n",
    "    alpha = np.zeros(intervals.size - 1)\n",
    "    \n",
    "    v_1_tilde = np.zeros(M)\n",
    "     \n",
    "    for k in range(intervals.size - 1):\n",
    "        leftPoint = intervals[k]\n",
    "        \n",
    "        # Array de taille M de booléens True/False\n",
    "        insideCell = np.logical_and( leftPoint <= W1, W1 < leftPoint+step )         \n",
    "        \n",
    "        # W2[insideCell]: la valeur W_2[m] est conservée uniquement si insideCell[m] = True\n",
    "        if (np.size(insideCell)>0):\n",
    "            X_T2 = MBG(x0, T2, sigma, W2[insideCell])\n",
    "        \n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul des\n",
    "        ## coefficients alpha[k]\n",
    "        #############################################\n",
    "            alpha[k]=np.mean(np.maximum(K-X_T2,0))\n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul de l'approximation\n",
    "        ## empirique v_1_tilde(W1) (array de taille M)\n",
    "        #############################################\n",
    "        v_1_tilde[insideCell]=alpha[k]\n",
    "     \n",
    "    return alpha, v_1_tilde\n",
    " \n",
    "time3 = time()\n",
    " \n",
    "alpha, v_1_tilde = regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma) \n",
    "\n",
    "################################################\n",
    "## TO DO: Completer avec le calcul du prix\n",
    "## par regression empirique u_tilde_0^M \n",
    "\n",
    "u_1_tilde=np.maximum(v_1_tilde, np.maximum(K-X1,0))\n",
    "prix_RegrEmp = np.maximum(np.maximum(K-x0,0),np.mean(u_1_tilde))\n",
    "################################################\n",
    "time4 = time()\n",
    " \n",
    "print(\"Prix par regression empirique = %1.4f\" %prix_RegrEmp)\n",
    "print(\"Time: %1.4f \\n\" %(time4 - time3 + timeSimulations))\n",
    " \n",
    "######################################\n",
    "## On peut afficher la vraie fonction\n",
    "## v_1 et son approximation empirique\n",
    "## pour comparaison\n",
    "#####################################\n",
    "x = np.linspace(-a, a, 100)\n",
    " \n",
    "v_1_exact = fonction_v_1(x0, T1, T2, K, x, sigma)\n",
    " \n",
    "plt.plot(x, v_1_exact, color=\"b\", label=\"$v_1$\")\n",
    " \n",
    "plt.step(intervals, np.append(alpha, alpha[-1]), where=\"post\", color=\"r\", label=r\"$\\tilde{v}_1$\")\n",
    " \n",
    "plt.xlabel(\"valeurs de $W_1$\", fontsize=17)\n",
    "plt.legend(loc=\"best\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Prix par _Simulations dans les simulations_ (ou _Nested Monte-Carlo_)__. L'estimateur de $u_0^M$ est\n",
    "$$\n",
    "\\hat{u}_0^{M} = \\max \\Bigl\\{ (K-x_0)^+,\n",
    "\\frac 1M \\sum_{m = 1}^M \\max\\left( (K - X_{1}^m)^+, \\hat{v}_{1}^m \\right)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où pour tout $m$, $\\hat{v}_{1}^m$ est obtenue à partir d'un échantillon de $M$ simulations i.i.d.\n",
    "de la loi de $W_2$ conditionellement à $W_1 = x$ calculée en $x = W_1^m$, notées \n",
    "$(W_2^{m,m'})_{1 \\le m' \\le M}$:\n",
    "$$\n",
    "\\hat{v}_{1}^m = \\frac1{M} \\sum_{m' = 1}^M \\bigl(K - x_0 \\, e^{-\\frac12 \\sigma^2 T_2 + \\sigma \\, W_2^{m,m'}} \\bigr)^+.\n",
    "$$\n",
    "    (a) Quelle est la loi de $W_2$ conditionelle à $W_1 = x$? Pour chaque $m$, simuler les $M$ tirages $W_2^{m, m'}$ suivant cette loi conditionnelle en $x =W_1^m$.\n",
    "    \n",
    "    (b) Compléter le calcul de cet estimateur dans le code ci-dessous, et comparer avec les méthodes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix Sim dans sim = 0.2484\n",
      "Time: 1.0036 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "#### 3. Prix \"simulations dans les simulations\"\n",
    "###################################################\n",
    " \n",
    "###################################################\n",
    "## On genere M tirages de X2 pour chaque valeur\n",
    "## dans l'echantillon X1.\n",
    "## Il faudra donc repeter les tirages de M gaussiennes iid \n",
    "## POUR CHAQUE valeur de X1.\n",
    "###################################################\n",
    "sum_u_1 = 0.\n",
    " \n",
    "time7 = time()\n",
    " \n",
    "for m, w1 in enumerate(W1):\n",
    "    G = np.random.randn(M)\n",
    "     \n",
    "    ###################################################\n",
    "    ## To Do: completer avec\n",
    "    ## - les tirages de W_2 conditionnellement a W1 = w1\n",
    "    ## - la mise a jour de la somme des contributions à\n",
    "    ##   la variable u_1\n",
    "    W2 = w1 + np.sqrt(T2 - T1) * G\n",
    "    #print(W2)\n",
    "    ## On implemente v_1_hat\n",
    "    v_1_hat = np.mean( np.maximum(K - MBG(x0, T2, sigma, W2),0) )\n",
    "    \n",
    "    max_courant = np.maximum( np.maximum(K - MBG(x0, T1, sigma, w1),0), v_1_hat)\n",
    "    \n",
    "    sum_u_1 += max_courant\n",
    "    ###################################################\n",
    "\n",
    "u_0 = np.maximum( np.maximum(K-x0,0.), sum_u_1/M )\n",
    "    \n",
    "time8 = time()\n",
    " \n",
    "print(\"Prix Sim dans sim = %1.4f\" %u_0)\n",
    "print(\"Time: %1.4f\" %(time8 - time7), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Prix Longstaff-Schwartz:__\n",
    "\n",
    "   Enfin, il est aussi possible d'approcher le temps d'arrêt $\\tau^*$ (qui, pour rappel, est une variable aléatoire) qui atteint l'optimum dans le problème originaire, c'est à dire $\\tau^*$ tel que\n",
    "$$\n",
    "{\\mathbb E} \\left[ (K - X_{\\tau^*})^+ \\right] =\n",
    "\\sup_{\\tau \\, \\in \\, \\mathcal{T}_2 } {\\mathbb E} \\left[ (K - X_\\tau)^+ \\right]\n",
    "$$\n",
    "   \n",
    "   Cette approche est appélée méthode de Longstaff-Schwartz en référence à l'article _[F. Longstaff, E. Schwartz, Valuing American Options by Simulation: A Simple Least-Squares Approach. The Review of Financial Studies, 2001]_.\n",
    "   \n",
    "   On peut montrer les propriétés suivantes (qui restent vraies pour le problème à $n$ dates):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ On pose $\\tau^\\star = \\min\\{i\\ge 0 : Y_i = (K - X_i)^+ \\}$ et on note $(Y^\\star_i)_{0\\le i \\le 2}$ le processus arrêté $Y^\\star_i = Y_{i \\wedge \\tau^\\star}$. Montrer que $\\tau^\\star \\in \\mathcal{T}_2$ et que\n",
    "$$\n",
    "Y^\\star_i = \\mathbb{E} \\left[Y^\\star_{i+1} \\big|\\mathcal{F}_i \\right].\n",
    "$$\n",
    "\n",
    "  (_Indication_: écrire $Y_{i \\wedge \\tau^\\star} = 1_{i < \\tau^\\star} Y_i \\, + \\, 1_{i \\ge \\tau^\\star} Y_{\\tau^\\star}$ et observer que sur l'événement $\\{i < \\tau^\\star\\}$, on a $Y_i = \\mathbb{E}[Y_{i+1}|\\mathcal{F}_i]$.)\n",
    "\n",
    "\n",
    "+ Utiliser le processus $(Y^\\star_i)_{0\\le i \\le 2}$ pour montrer que $\\tau^\\star$ est un temps d'arrêt optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ On remarquera que la construction de $\\tau^*$ ci-dessus nécessite de comparer la variable $(K - X_i)^+$ à la valeur courante de $Y_i = u_i(W_i)$.\n",
    "\n",
    "En remplaçant la vraie fonction $u_i$ par la fonction $\\tilde{u}_i$ estimée par régression empirique, on obtient l'estimateur\n",
    "\n",
    "$$\n",
    "\\check{u}_0^M = \\frac1{M} \\sum_{m = 1}^M (K - X^{m}_{\\tau_m})^+,\n",
    "\\qquad\n",
    "\\mbox{où }\n",
    "\\tau_m = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "0 & \\mbox{si } (K-x_0)^+ \\ge \\tilde u_0^M\n",
    "\\\\\n",
    "1 & \\mbox{si } (K-x_0)^+ < \\tilde u_0^M \\mbox{ et } (K-X_1^m)^+ \\ge \\tilde{u}_1(W_1^m)\n",
    "\\\\\n",
    "2 & \\mbox{sinon}.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Compléter le calcul de cet estimateur dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix Longstaff-Schwartz = 0.2473\n",
      "Time: 0.0042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "### 4. Prix Longstaff-Schwartz\n",
    "#######################################\n",
    "time5 = time()\n",
    " \n",
    "def tempsArretOptimal(X1, approx_empirique_T1, K, x0, M):\n",
    "    ## On réutilise l'approximation empirique definie\n",
    "    ## plus haut, correspondant a v_1_tilde\n",
    "    gain_T1 = np.maximum(K - X1, 0.)\n",
    "    \n",
    "    u_1_tilde = np.maximum(gain_T1, approx_empirique_T1)\n",
    "     \n",
    "    mean_0 = np.mean(u_1_tilde)\n",
    "     \n",
    "    if np.maximum((K-x0), 0.) >= mean_0:\n",
    "        return np.zeros(M)\n",
    "    else:\n",
    "        tau = 1 * (u_1_tilde <= gain_T1) \\\n",
    "              + 2 * (u_1_tilde > gain_T1)\n",
    "     \n",
    "    return tau\n",
    " \n",
    "###################################################\n",
    "## To Do: completer avec le calcul\n",
    "## - du temps d'arret optimal tau (echantillon tau_m)\n",
    "## - de l'estimateur Longstaff-Schwartz du prix\n",
    "##\n",
    "tau = tempsArretOptimal(X1, v_1_tilde, K, x0, M)\n",
    "\n",
    "\n",
    "X_tau=(tau==0)*x0+(tau==1)*X1+(tau==2)*X2\n",
    "    \n",
    "    \n",
    "echantillon = np.maximum(K - X_tau,0)\n",
    "    \n",
    "estimateur_LongSchwartz = np.mean(echantillon)\n",
    "###################################################\n",
    " \n",
    "time6 = time()\n",
    " \n",
    "print(\"Prix Longstaff-Schwartz = %1.4f\" %estimateur_LongSchwartz)\n",
    "print(\"Time: %1.4f \\n\" %(time6 - time5 + time4 - time3 + timeSimulations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
